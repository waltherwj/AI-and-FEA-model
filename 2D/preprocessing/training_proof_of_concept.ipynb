{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING\n",
    "This notebook has as an objective to use a folder containing the formated .npy files to train a deep learning model that can be used in lieu of an FEA model to any accuracy above random, for a proof of concept that it is possible to do so, such that further research can be done afterward to optimize architecture, hyperparameters and data being fed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pathlib\n",
    "import PREPROCESSING_splitting as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, create a class to load the files that are to be fed to the neural network, \n",
    "## for both the inputs and the outputs. To avoid confusion I'll refer to the inputs to the \n",
    "## FEA model as 'bound_conds' (boundary conditions), and the outputs as 'targets', while what \n",
    "## is fed into the neural network will be called an \"input\", and the output of the neural network \"prediction\"\n",
    "## this function should probably be transformed into a dataloader later for a larger dataset, \n",
    "## but for now we'll keep it like this\n",
    "\n",
    "def get_dataset(dataset_path, glob_parameter = '*.npy'):\n",
    "    # concatenates all samples into a list of boundary conditions and a list of targets\n",
    "    \n",
    "    # set paths\n",
    "    bound_cond_path = pathlib.Path(dataset_path, 'input')\n",
    "    targets_path = pathlib.Path(dataset_path, 'output')\n",
    "\n",
    "    test = pathlib.Path('D:/')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # check if folder path is correct\n",
    "    if bound_cond_path.is_dir() and targets_path.is_dir():\n",
    "        print('path contains \\'input\\' and \\'output\\'')\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception (f'Argument dataset_path: {dataset_path} should contain folders ..\\input and ..\\output. Please check path')\n",
    "    \n",
    "    #create iterators for files\n",
    "    bound_cond_iterator = bound_cond_path.glob(glob_parameter)\n",
    "    targets_iterator = targets_path.glob(glob_parameter)\n",
    "    \n",
    "    #zip them to ensure that they are going through the same samples \n",
    "    samples_iterator = zip(bound_cond_iterator, targets_iterator)\n",
    "    \n",
    "    boundary_conditions = np.array([])\n",
    "    targets = np.array([])\n",
    "    \n",
    "    for boundary_condition_files, targets_files in samples_iterator:\n",
    "        if split.get_number(boundary_condition_files.name) == split.get_number(targets_files.name):\n",
    "            \n",
    "            boundary_conditions_temp = np.load(boundary_condition_files)\n",
    "            targets_temp = np.load(targets_files)\n",
    "            \n",
    "            #start array if it hasn't been started yet\n",
    "            if boundary_conditions.size == 0 and targets.size == 0:\n",
    "                boundary_conditions = boundary_conditions_temp\n",
    "                targets = targets_temp\n",
    "            else:\n",
    "                boundary_conditions = np.concatenate((boundary_conditions, boundary_conditions_temp), axis = 0)\n",
    "                targets = np.concatenate((targets, targets_temp), axis = 0)\n",
    "        else:\n",
    "            raise Exception('the samples in the iterator are not synced')\n",
    "    \n",
    "    return torch.from_numpy(boundary_conditions).float(), torch.from_numpy(targets).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path contains 'input' and 'output'\n",
      "torch.Size([102, 7, 32, 32])\n",
      "torch.Size([102, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "folders_path =  pathlib.Path('D:/Ansys Simulations/Project/2D/data/proof_of_concept/scaled/arrays')\n",
    "dataset = get_dataset(dataset_path = folders_path)\n",
    "print(dataset[0].shape)\n",
    "print(dataset[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 32, 32])\n",
      "torch.Size([1, 14, 32, 32])\n",
      "torch.Size([1, 16, 32, 32])\n",
      "torch.Size([1, 14, 32, 32])\n",
      "torch.Size([1, 10, 32, 32])\n",
      "torch.Size([1, 7, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0591,  0.0511,  0.0485,  ...,  0.0385,  0.0486,  0.0397],\n",
       "          [ 0.0462,  0.0245,  0.0104,  ..., -0.0054,  0.0102,  0.0179],\n",
       "          [ 0.0335,  0.0164,  0.0012,  ..., -0.0124,  0.0033,  0.0166],\n",
       "          ...,\n",
       "          [ 0.0797,  0.0754,  0.0406,  ..., -0.0079,  0.0116,  0.0210],\n",
       "          [ 0.0763,  0.0732,  0.0416,  ...,  0.0043,  0.0214,  0.0216],\n",
       "          [ 0.0419,  0.0440,  0.0163,  ...,  0.0052,  0.0110,  0.0320]],\n",
       "\n",
       "         [[-0.0301, -0.0742, -0.0626,  ..., -0.0729, -0.0654, -0.0790],\n",
       "          [-0.0292, -0.0947, -0.0963,  ..., -0.1063, -0.1130, -0.1121],\n",
       "          [-0.0147, -0.0895, -0.0957,  ..., -0.1042, -0.1094, -0.1091],\n",
       "          ...,\n",
       "          [ 0.0040, -0.0509, -0.0415,  ..., -0.0947, -0.0993, -0.1022],\n",
       "          [ 0.0064, -0.0695, -0.0642,  ..., -0.1030, -0.1089, -0.1090],\n",
       "          [-0.0155, -0.0533, -0.0523,  ..., -0.0852, -0.0889, -0.0764]],\n",
       "\n",
       "         [[ 0.1804,  0.1742,  0.1745,  ...,  0.1702,  0.1765,  0.1904],\n",
       "          [ 0.2035,  0.1667,  0.1811,  ...,  0.1759,  0.1794,  0.2045],\n",
       "          [ 0.2046,  0.1718,  0.1889,  ...,  0.1821,  0.1842,  0.2093],\n",
       "          ...,\n",
       "          [ 0.1995,  0.1594,  0.1817,  ...,  0.1804,  0.1854,  0.2105],\n",
       "          [ 0.1934,  0.1600,  0.1830,  ...,  0.1805,  0.1801,  0.2086],\n",
       "          [ 0.1982,  0.1519,  0.1778,  ...,  0.1665,  0.1605,  0.1855]]]],\n",
       "       grad_fn=<HardtanhBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define the neural network's general shape\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        ## convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 7, out_channels = 14, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 14, out_channels = 16, kernel_size = 3, padding = 1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels = 16, out_channels = 14, kernel_size = 3, padding = 1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels = 14, out_channels = 10, kernel_size = 3, padding = 1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels = 10, out_channels = 7, kernel_size = 3, padding = 1)\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels = 7, out_channels = 3, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        ## activation\n",
    "        self.hardtanh = nn.Hardtanh()\n",
    "        \n",
    "        \n",
    "        ##possible for later: MultiheadAttention\n",
    "        \n",
    "    def forward(self, boundary_conditions):\n",
    "        print(boundary_conditions.shape)\n",
    "        x = self.conv1(boundary_conditions)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.deconv4(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "    \n",
    "net = ConvNet().float()\n",
    "\n",
    "## test to see if getting the correct size\n",
    "net.forward(dataset[0][0:1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a general training loop\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
