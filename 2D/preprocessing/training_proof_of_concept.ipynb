{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING\n",
    "This notebook has as an objective to use a folder containing the formated .npy files to train a deep learning model that can be used in lieu of an FEA model to any accuracy above random, for a proof of concept that it is possible to do so, such that further research can be done afterward to optimize architecture, hyperparameters and data being fed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pathlib\n",
    "import PREPROCESSING_splitting as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, create a class to load the files that are to be fed to the neural network, \n",
    "## for both the inputs and the outputs. To avoid confusion I'll refer to the inputs to the \n",
    "## FEA model as 'bound_conds' (boundary conditions), and the outputs as 'targets', while what \n",
    "## is fed into the neural network will be called an \"input\", and the output of the neural network \"prediction\"\n",
    "## this function should probably be transformed into a dataloader later for a larger dataset, \n",
    "## but for now we'll keep it like this\n",
    "\n",
    "def get_dataset(dataset_path, glob_parameter = '*.npy'):\n",
    "    # concatenates all samples into a list of boundary conditions and a list of targets\n",
    "    \n",
    "    # set paths\n",
    "    bound_cond_path = pathlib.Path(dataset_path, 'input')\n",
    "    targets_path = pathlib.Path(dataset_path, 'output')\n",
    "\n",
    "    test = pathlib.Path('D:/')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # check if folder path is correct\n",
    "    if bound_cond_path.is_dir() and targets_path.is_dir():\n",
    "        print('path contains \\'input\\' and \\'output\\'')\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception (f'Argument dataset_path: {dataset_path} should contain folders ..\\input and ..\\output. Please check path')\n",
    "    \n",
    "    #create iterators for files\n",
    "    bound_cond_iterator = bound_cond_path.glob(glob_parameter)\n",
    "    targets_iterator = targets_path.glob(glob_parameter)\n",
    "    \n",
    "    #zip them to ensure that they are going through the same samples \n",
    "    samples_iterator = zip(bound_cond_iterator, targets_iterator)\n",
    "    \n",
    "    boundary_conditions = np.array([])\n",
    "    targets = np.array([])\n",
    "    \n",
    "    for boundary_condition_files, targets_files in samples_iterator:\n",
    "        if split.get_number(boundary_condition_files.name) == split.get_number(targets_files.name):\n",
    "            \n",
    "            boundary_conditions_temp = np.load(boundary_condition_files)\n",
    "            targets_temp = np.load(targets_files)\n",
    "            \n",
    "            #start array if it hasn't been started yet\n",
    "            if boundary_conditions.size == 0 and targets.size == 0:\n",
    "                boundary_conditions = boundary_conditions_temp\n",
    "                targets = targets_temp\n",
    "            else:\n",
    "                boundary_conditions = np.concatenate((boundary_conditions, boundary_conditions_temp), axis = 0)\n",
    "                targets = np.concatenate((targets, targets_temp), axis = 0)\n",
    "        else:\n",
    "            raise Exception('the samples in the iterator are not synced')\n",
    "    \n",
    "    return torch.from_numpy(boundary_conditions).float(), torch.from_numpy(targets).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path contains 'input' and 'output'\n",
      "torch.Size([102, 7, 32, 32])\n",
      "torch.Size([102, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "folders_path =  pathlib.Path('D:/Ansys Simulations/Project/2D/data/proof_of_concept/scaled/arrays')\n",
    "dataset = get_dataset(dataset_path = folders_path)\n",
    "print(dataset[0].shape)\n",
    "print(dataset[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 32, 32])\n",
      "torch.Size([1, 14, 32, 32])\n",
      "torch.Size([1, 16, 32, 32])\n",
      "torch.Size([1, 14, 32, 32])\n",
      "torch.Size([1, 10, 32, 32])\n",
      "torch.Size([1, 7, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1144, -0.0968, -0.0917,  ..., -0.0905, -0.1017, -0.0330],\n",
       "          [-0.1218, -0.1212, -0.1189,  ..., -0.1210, -0.1391, -0.0570],\n",
       "          [-0.1188, -0.1318, -0.1390,  ..., -0.1414, -0.1591, -0.0735],\n",
       "          ...,\n",
       "          [-0.1088, -0.1017, -0.1053,  ..., -0.1375, -0.1574, -0.0720],\n",
       "          [-0.1025, -0.1008, -0.1038,  ..., -0.1360, -0.1500, -0.0807],\n",
       "          [-0.1087, -0.1322, -0.1290,  ..., -0.1613, -0.1671, -0.1251]],\n",
       "\n",
       "         [[-0.0141,  0.0011,  0.0099,  ...,  0.0135,  0.0124,  0.0049],\n",
       "          [-0.0269,  0.0310,  0.0334,  ...,  0.0353,  0.0386,  0.0231],\n",
       "          [-0.0157,  0.0387,  0.0457,  ...,  0.0492,  0.0518,  0.0265],\n",
       "          ...,\n",
       "          [-0.0320,  0.0673,  0.0749,  ...,  0.0621,  0.0643,  0.0328],\n",
       "          [-0.0366,  0.0661,  0.0687,  ...,  0.0592,  0.0601,  0.0354],\n",
       "          [-0.0399,  0.0305,  0.0290,  ...,  0.0287,  0.0328,  0.0099]],\n",
       "\n",
       "         [[ 0.1067,  0.0982,  0.0944,  ...,  0.0940,  0.0895,  0.0903],\n",
       "          [ 0.0735,  0.0710,  0.0657,  ...,  0.0751,  0.0754,  0.0900],\n",
       "          [ 0.0791,  0.0726,  0.0685,  ...,  0.0767,  0.0790,  0.0939],\n",
       "          ...,\n",
       "          [ 0.1041,  0.1153,  0.1154,  ...,  0.0810,  0.0845,  0.0995],\n",
       "          [ 0.1049,  0.1245,  0.1168,  ...,  0.0874,  0.0942,  0.1068],\n",
       "          [ 0.0647,  0.1053,  0.0958,  ...,  0.0825,  0.0889,  0.0988]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0212,  0.0263,  0.0311,  ...,  0.0275,  0.0233,  0.0514],\n",
       "          [ 0.0581,  0.0779,  0.0842,  ...,  0.0806,  0.0874,  0.1035],\n",
       "          [ 0.0808,  0.1092,  0.1155,  ...,  0.1107,  0.1167,  0.1174],\n",
       "          ...,\n",
       "          [ 0.0717,  0.1410,  0.1356,  ...,  0.1120,  0.1175,  0.1208],\n",
       "          [ 0.0808,  0.1487,  0.1496,  ...,  0.1122,  0.1177,  0.1222],\n",
       "          [ 0.1254,  0.1711,  0.1719,  ...,  0.1428,  0.1537,  0.1298]],\n",
       "\n",
       "         [[ 0.0754,  0.0729,  0.0782,  ...,  0.0787,  0.0761,  0.0858],\n",
       "          [ 0.0574,  0.0467,  0.0612,  ...,  0.0611,  0.0607,  0.0960],\n",
       "          [ 0.0423,  0.0369,  0.0476,  ...,  0.0503,  0.0524,  0.0963],\n",
       "          ...,\n",
       "          [ 0.0474,  0.0432,  0.0659,  ...,  0.0532,  0.0535,  0.0968],\n",
       "          [ 0.0401,  0.0580,  0.0776,  ...,  0.0608,  0.0674,  0.1068],\n",
       "          [ 0.0614,  0.0657,  0.0860,  ...,  0.0691,  0.0663,  0.1102]],\n",
       "\n",
       "         [[-0.0671, -0.0482, -0.0495,  ..., -0.0498, -0.0595, -0.0609],\n",
       "          [-0.0566, -0.0418, -0.0463,  ..., -0.0408, -0.0449, -0.0318],\n",
       "          [-0.0423, -0.0218, -0.0229,  ..., -0.0211, -0.0220, -0.0220],\n",
       "          ...,\n",
       "          [-0.0436, -0.0067, -0.0055,  ..., -0.0145, -0.0163, -0.0192],\n",
       "          [-0.0245,  0.0114,  0.0189,  ..., -0.0150, -0.0150, -0.0187],\n",
       "          [-0.0675, -0.0311, -0.0227,  ..., -0.0557, -0.0509, -0.0291]]]],\n",
       "       grad_fn=<HardtanhBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define the neural network's general shape\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        ## convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 7, out_channels = 14, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 14, out_channels = 16, kernel_size = 3, padding = 1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels = 16, out_channels = 14, kernel_size = 3, padding = 1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels = 14, out_channels = 10, kernel_size = 3, padding = 1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels = 10, out_channels = 7, kernel_size = 3, padding = 1)\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels = 7, out_channels = 4, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        ## activation\n",
    "        self.hardtanh = nn.Hardtanh()\n",
    "        \n",
    "        \n",
    "        ##possible for later: MultiheadAttention\n",
    "        \n",
    "    def forward(self, boundary_conditions):\n",
    "        print(boundary_conditions.shape)\n",
    "        x = self.conv1(boundary_conditions)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.hardtanh(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = ConvNet().float()\n",
    "net.forward(dataset[0][0:1,:,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
